{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ticlemXaNyrIHoAawXiwNA6ZYyktxHpg",
      "authorship_tag": "ABX9TyMmO4dw+Nh16/2qZW+gFS/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enverakbacak/EMIR/blob/main/myGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3R9rpEBrAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee0a5d1-761f-43c9-d794-2c166622f8c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dMXK7DdlEYN",
        "outputId": "4adc51e2-1d1f-4dfa-f1d1-d9ea8c4f9ddd"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uEsYlKUCtaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9821de-0326-403e-b441-9abba6612db5"
      },
      "source": [
        "cd drive/MyDrive/ColabNotebooks/generators/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/generators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEjO8gzuR61z"
      },
      "source": [
        "#coding=utf-8\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import sys,os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import time\n",
        "import glob\n",
        "import os, os.path\n",
        "import re\n",
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4E7j2-YhZlK"
      },
      "source": [
        "def generator(samples, labels, batch_size=16):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        "\n",
        "    while True: # Loop forever so the generator never terminates\n",
        "\n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            label_samples = labels[offset:offset+batch_size]\n",
        "\n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            y_train = []\n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "              #filename = batch_sample\n",
        "              image = plt.imread(batch_sample[0])\n",
        "              image = cv2.resize(image,(229, 229))\n",
        "              X_train.append(image)\n",
        "            X_train = np.array(X_train)\n",
        "            X_train = X_train.astype(float)\n",
        "            #print(X_train.dtype)\n",
        "            #from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "            #X_train = preprocess_input(X_train) # preprocessing the input data\n",
        "\n",
        "            for label_sample in label_samples:\n",
        "              y_train.append(label_sample)\n",
        "            y_train = np.array(y_train)\n",
        "            y_train = y_train.astype(float)\n",
        "            #print(y_train.dtype)\n",
        "\n",
        "            # The generator-y part: yield the next training batch\n",
        "            yield X_train, y_train\n",
        "\n",
        "\n",
        "# Import list of train and validation data (image filenames and image labels)\n",
        "# Note this is not valid code.\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbqiZOcyhgcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6181cd4-7580-4d7f-f183-9ba62a0ccafc"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "from csv import reader\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('data.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    # Check file as empty\n",
        "    if header != None:\n",
        "        # Iterate over each row after the header in the csv\n",
        "        for row in csv_reader:\n",
        "            # row variable is a list that represents a row in csv\n",
        "            data.append(row)\n",
        "data=np.array(data)\n",
        "print(data.dtype)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('Y.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    # Check file as empty\n",
        "    if header != None:\n",
        "        # Iterate over each row after the header in the csv\n",
        "        for row in csv_reader:\n",
        "            # row variable is a list that represents a row in csv\n",
        "            labels.append(row)\n",
        "labels=np.array(labels)\n",
        "print(labels.shape)\n",
        "print(labels.dtype)\n",
        "\n",
        "#labels = np.asarray(labels).astype('float32').reshape((-1,1))\n",
        "#print(labels.shape[:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<U21\n",
            "(2000, 1)\n",
            "(2000, 5)\n",
            "<U1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PglzDrkdDrK"
      },
      "source": [
        "# Create generator\n",
        "train_generator = generator(data, labels, batch_size=32)\n",
        "x,y = next(train_generator)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNMJXik72U3c",
        "outputId": "a051d4e4-7cba-4a54-9dc8-268dce8fb411"
      },
      "source": [
        "print ('x_shape: ', x.shape)\n",
        "print ('labels_shape: ', y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_shape:  (32, 229, 229, 3)\n",
            "labels_shape:  (32, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJib9I44HpC"
      },
      "source": [
        "x,y = next(train_generator)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAMCRYdA3O61",
        "outputId": "89d03e1b-551e-48d1-b20c-52c0f8f196a5"
      },
      "source": [
        "print(y[:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_QFvM6thnrS",
        "outputId": "d1b291fb-9686-421e-ffe2-256e1c21b275"
      },
      "source": [
        "image_size = 229\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "batch_size = 16\n",
        "hash_bits = 64\n",
        "inputs    = tensorflow.keras.Input(shape = (image_size, image_size,3))\n",
        "x         = base_model(inputs)\n",
        "flatten   = Flatten()(x)\n",
        "Dense_1   = Dense(1024)(flatten)\n",
        "#avgPool = GlobalAveragePooling2D()(Dense_1)\n",
        "Dense_2 = Dense(hash_bits ,activation='sigmoid')(Dense_1)\n",
        "Dense_3 = Dense(5, activation='sigmoid')(Dense_2)\n",
        "model = Model(inputs, Dense_3)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "sgd = SGD(learning_rate=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "def c_loss_1(y_true, y_pred):\n",
        "    return  tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def c_loss_2(noise_1, noise_2):\n",
        "    #noise_1 = tf.cast(Dense_2 > 0.5 , tf.float32 )\n",
        "    noise_1 = (Dense_2 > 0.5 )\n",
        "    noise_2 = Dense_2\n",
        "    return  tf.keras.losses.binary_crossentropy(noise_1, noise_2)\n",
        "\n",
        "model.compile(loss = [c_loss_1, c_loss_2],  optimizer=sgd, metrics=['accuracy'],)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 229, 229, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              52429824  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 74,298,533\n",
            "Trainable params: 52,495,749\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGNPNyRUVqib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10558be8-0e43-4c5a-e06d-43121f099b5a"
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch = math.ceil(len(labels) // batch_size), verbose=1, epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 21s 120ms/step - loss: 0.6292 - accuracy: 0.1603\n",
            "Epoch 2/300\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.5787 - accuracy: 0.2868\n",
            "Epoch 3/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.5606 - accuracy: 0.3080\n",
            "Epoch 4/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.5548 - accuracy: 0.2974\n",
            "Epoch 5/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.5475 - accuracy: 0.2742\n",
            "Epoch 6/300\n",
            "125/125 [==============================] - 14s 116ms/step - loss: 0.5406 - accuracy: 0.2984\n",
            "Epoch 7/300\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.5322 - accuracy: 0.3798\n",
            "Epoch 8/300\n",
            "125/125 [==============================] - 14s 115ms/step - loss: 0.5280 - accuracy: 0.3770\n",
            "Epoch 9/300\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.5248 - accuracy: 0.3972\n",
            "Epoch 10/300\n",
            "125/125 [==============================] - 15s 116ms/step - loss: 0.5218 - accuracy: 0.3808\n",
            "Epoch 11/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.5204 - accuracy: 0.3727\n",
            "Epoch 12/300\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.5203 - accuracy: 0.3536\n",
            "Epoch 13/300\n",
            "125/125 [==============================] - 14s 115ms/step - loss: 0.5192 - accuracy: 0.3979\n",
            "Epoch 14/300\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.5156 - accuracy: 0.3987\n",
            "Epoch 15/300\n",
            "125/125 [==============================] - 14s 116ms/step - loss: 0.5140 - accuracy: 0.4037\n",
            "Epoch 16/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.5105 - accuracy: 0.4123\n",
            "Epoch 17/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.5094 - accuracy: 0.4181\n",
            "Epoch 18/300\n",
            "125/125 [==============================] - 15s 120ms/step - loss: 0.5078 - accuracy: 0.4163\n",
            "Epoch 19/300\n",
            "125/125 [==============================] - 15s 117ms/step - loss: 0.5068 - accuracy: 0.4126\n",
            "Epoch 20/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.5056 - accuracy: 0.4138\n",
            "Epoch 21/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.5041 - accuracy: 0.4241\n",
            "Epoch 22/300\n",
            "125/125 [==============================] - 14s 116ms/step - loss: 0.5024 - accuracy: 0.4156\n",
            "Epoch 23/300\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.5030 - accuracy: 0.4040\n",
            "Epoch 24/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.5017 - accuracy: 0.4068\n",
            "Epoch 25/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.4996 - accuracy: 0.4234\n",
            "Epoch 26/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4983 - accuracy: 0.4249\n",
            "Epoch 27/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4982 - accuracy: 0.4294\n",
            "Epoch 28/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4976 - accuracy: 0.4274\n",
            "Epoch 29/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4982 - accuracy: 0.4244\n",
            "Epoch 30/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4968 - accuracy: 0.4257\n",
            "Epoch 31/300\n",
            "125/125 [==============================] - 14s 116ms/step - loss: 0.4962 - accuracy: 0.4294\n",
            "Epoch 32/300\n",
            "125/125 [==============================] - 15s 120ms/step - loss: 0.4964 - accuracy: 0.4309\n",
            "Epoch 33/300\n",
            "125/125 [==============================] - 14s 115ms/step - loss: 0.4967 - accuracy: 0.4289\n",
            "Epoch 34/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4965 - accuracy: 0.4158\n",
            "Epoch 35/300\n",
            "125/125 [==============================] - 15s 116ms/step - loss: 0.4942 - accuracy: 0.4342\n",
            "Epoch 36/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.4931 - accuracy: 0.4380\n",
            "Epoch 37/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.4917 - accuracy: 0.4378\n",
            "Epoch 38/300\n",
            "125/125 [==============================] - 14s 116ms/step - loss: 0.4926 - accuracy: 0.4400\n",
            "Epoch 39/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4974 - accuracy: 0.4342\n",
            "Epoch 40/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.4924 - accuracy: 0.4504\n",
            "Epoch 41/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4926 - accuracy: 0.4304\n",
            "Epoch 42/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4960 - accuracy: 0.4352\n",
            "Epoch 43/300\n",
            "125/125 [==============================] - 15s 117ms/step - loss: 0.4898 - accuracy: 0.4509\n",
            "Epoch 44/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4886 - accuracy: 0.4493\n",
            "Epoch 45/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4893 - accuracy: 0.4367\n",
            "Epoch 46/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.4862 - accuracy: 0.4466\n",
            "Epoch 47/300\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 0.4867 - accuracy: 0.4428\n",
            "Epoch 48/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4837 - accuracy: 0.4536\n",
            "Epoch 49/300\n",
            "125/125 [==============================] - 14s 115ms/step - loss: 0.4845 - accuracy: 0.4496\n",
            "Epoch 50/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4816 - accuracy: 0.4491\n",
            "Epoch 51/300\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.4834 - accuracy: 0.4587\n",
            "Epoch 52/300\n",
            "125/125 [==============================] - 15s 117ms/step - loss: 0.4795 - accuracy: 0.4708\n",
            "Epoch 53/300\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.4796 - accuracy: 0.4708\n",
            "Epoch 54/300\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.4803 - accuracy: 0.4632\n",
            "Epoch 55/300\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 0.4771 - accuracy: 0.4801\n",
            "Epoch 56/300\n",
            "125/125 [==============================] - 15s 118ms/step - loss: 0.4770 - accuracy: 0.4781\n",
            "Epoch 57/300\n",
            "115/125 [==========================>...] - ETA: 1s - loss: 0.4706 - accuracy: 0.4975"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}