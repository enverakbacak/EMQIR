{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ticlemXaNyrIHoAawXiwNA6ZYyktxHpg",
      "authorship_tag": "ABX9TyNITrNh3IzdGtiiaYrTcuPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enverakbacak/EMIR/blob/main/myGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3R9rpEBrAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c316fd-6225-4ec5-af78-e45076184ba5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dMXK7DdlEYN",
        "outputId": "1cae936a-e487-4865-d524-144c5012253d"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uEsYlKUCtaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354996bd-3bca-47d1-df21-3b2e67d8964c"
      },
      "source": [
        "cd drive/MyDrive/ColabNotebooks/generators/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/generators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEjO8gzuR61z"
      },
      "source": [
        "#coding=utf-8\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import sys,os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import time\n",
        "import glob\n",
        "import os, os.path\n",
        "import re\n",
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4E7j2-YhZlK"
      },
      "source": [
        "def generator(samples, labels, batch_size=16):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        "\n",
        "    while True: # Loop forever so the generator never terminates\n",
        "\n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            label_samples = labels[offset:offset+batch_size]\n",
        "\n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            y_train = []\n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "              #filename = batch_sample\n",
        "              image = plt.imread(batch_sample[0])\n",
        "              image = cv2.resize(image,(229, 229))\n",
        "              X_train.append(image)\n",
        "            X_train = np.array(X_train)\n",
        "            X_train = X_train.astype(float)\n",
        "            #print(X_train.dtype)\n",
        "            #from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "            #X_train = preprocess_input(X_train) # preprocessing the input data\n",
        "\n",
        "            for label_sample in label_samples:\n",
        "              y_train.append(label_sample)\n",
        "            y_train = np.array(y_train)\n",
        "            y_train = y_train.astype(float)\n",
        "            #print(y_train.dtype)\n",
        "\n",
        "            # The generator-y part: yield the next training batch\n",
        "            yield X_train, y_train\n",
        "\n",
        "\n",
        "# Import list of train and validation data (image filenames and image labels)\n",
        "# Note this is not valid code.\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbqiZOcyhgcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b1fcc4-e7a1-4984-8e28-20075624ba79"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "from csv import reader\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('data.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    # Check file as empty\n",
        "    if header != None:\n",
        "        # Iterate over each row after the header in the csv\n",
        "        for row in csv_reader:\n",
        "            # row variable is a list that represents a row in csv\n",
        "            data.append(row)\n",
        "data=np.array(data)\n",
        "print(data.dtype)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('Y.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    # Check file as empty\n",
        "    if header != None:\n",
        "        # Iterate over each row after the header in the csv\n",
        "        for row in csv_reader:\n",
        "            # row variable is a list that represents a row in csv\n",
        "            labels.append(row)\n",
        "labels=np.array(labels)\n",
        "print(labels.shape)\n",
        "print(labels.dtype)\n",
        "\n",
        "#labels = np.asarray(labels).astype('float32').reshape((-1,1))\n",
        "#print(labels.shape[:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<U21\n",
            "(2000, 1)\n",
            "(2000, 5)\n",
            "<U1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PglzDrkdDrK"
      },
      "source": [
        "# Create generator\n",
        "train_generator = generator(data, labels, batch_size=32)\n",
        "x,y = next(train_generator)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNMJXik72U3c",
        "outputId": "04e5761f-4bd9-4c43-dccd-5faf10be4fc4"
      },
      "source": [
        "print ('x_shape: ', x.shape)\n",
        "print ('labels_shape: ', y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_shape:  (32, 229, 229, 3)\n",
            "labels_shape:  (32, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJib9I44HpC"
      },
      "source": [
        "x,y = next(train_generator)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAMCRYdA3O61",
        "outputId": "b29fa347-30a6-4067-91e1-7767ddabb8b1"
      },
      "source": [
        "print(y[:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_QFvM6thnrS",
        "outputId": "caf137c3-8a63-4302-b9b2-1a7b11fdd75e"
      },
      "source": [
        "image_size = 229\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "base_model.trainable = True\n",
        "\n",
        "batch_size = 16\n",
        "hash_bits = 64\n",
        "inputs    = tensorflow.keras.Input(shape = (image_size, image_size,3))\n",
        "x         = base_model(inputs)\n",
        "flatten   = Flatten()(x)\n",
        "Dense_1   = Dense(1024)(flatten)\n",
        "#avgPool = GlobalAveragePooling2D()(Dense_1)\n",
        "Dense_2 = Dense(hash_bits ,activation='sigmoid')(Dense_1)\n",
        "Dense_3 = Dense(5, activation='sigmoid')(Dense_2)\n",
        "model = Model(inputs, Dense_3)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "sgd = SGD(learning_rate=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "def c_loss_1(y_true, y_pred):\n",
        "    return  tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def c_loss_2(noise_1, noise_2):\n",
        "    #noise_1 = tf.cast(Dense_2 > 0.5 , tf.float32 )\n",
        "    noise_1 = (Dense_2 > 0.5 )\n",
        "    noise_2 = Dense_2\n",
        "    return  tf.keras.losses.binary_crossentropy(noise_1, noise_2)\n",
        "\n",
        "model.compile(loss = [c_loss_1, c_loss_2],  optimizer=sgd, metrics=['accuracy'],)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 229, 229, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              52429824  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 74,298,533\n",
            "Trainable params: 74,264,101\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGNPNyRUVqib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78235100-ca55-4d93-a43c-33557e4ae861"
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch = math.ceil(len(labels) // batch_size), verbose=1, epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 48s 287ms/step - loss: 0.6740 - accuracy: 0.1182\n",
            "Epoch 2/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.5755 - accuracy: 0.1172\n",
            "Epoch 3/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.5570 - accuracy: 0.1722\n",
            "Epoch 4/300\n",
            "125/125 [==============================] - 33s 265ms/step - loss: 0.5450 - accuracy: 0.2180\n",
            "Epoch 5/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.5342 - accuracy: 0.2676\n",
            "Epoch 6/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.5231 - accuracy: 0.3117\n",
            "Epoch 7/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.5130 - accuracy: 0.3528\n",
            "Epoch 8/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.5024 - accuracy: 0.3969\n",
            "Epoch 9/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4914 - accuracy: 0.4418\n",
            "Epoch 10/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4803 - accuracy: 0.4945\n",
            "Epoch 11/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4695 - accuracy: 0.5315\n",
            "Epoch 12/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4580 - accuracy: 0.5678\n",
            "Epoch 13/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.4470 - accuracy: 0.6041\n",
            "Epoch 14/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4358 - accuracy: 0.6366\n",
            "Epoch 15/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.4247 - accuracy: 0.6615\n",
            "Epoch 16/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4138 - accuracy: 0.6905\n",
            "Epoch 17/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.4028 - accuracy: 0.7122\n",
            "Epoch 18/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3917 - accuracy: 0.7334\n",
            "Epoch 19/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.3811 - accuracy: 0.7465\n",
            "Epoch 20/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3709 - accuracy: 0.7591\n",
            "Epoch 21/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3601 - accuracy: 0.7722\n",
            "Epoch 22/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3498 - accuracy: 0.7855\n",
            "Epoch 23/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3399 - accuracy: 0.7966\n",
            "Epoch 24/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.3306 - accuracy: 0.8012\n",
            "Epoch 25/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.3214 - accuracy: 0.8072\n",
            "Epoch 26/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3126 - accuracy: 0.8115\n",
            "Epoch 27/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.3040 - accuracy: 0.8143\n",
            "Epoch 28/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2962 - accuracy: 0.8150\n",
            "Epoch 29/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2886 - accuracy: 0.8191\n",
            "Epoch 30/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2808 - accuracy: 0.8170\n",
            "Epoch 31/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2735 - accuracy: 0.8198\n",
            "Epoch 32/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2663 - accuracy: 0.8196\n",
            "Epoch 33/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2597 - accuracy: 0.8193\n",
            "Epoch 34/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2534 - accuracy: 0.8203\n",
            "Epoch 35/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.2472 - accuracy: 0.8201\n",
            "Epoch 36/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.2413 - accuracy: 0.8206\n",
            "Epoch 37/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.2358 - accuracy: 0.8233\n",
            "Epoch 38/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2304 - accuracy: 0.8266\n",
            "Epoch 39/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.2254 - accuracy: 0.8261\n",
            "Epoch 40/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.2205 - accuracy: 0.8259\n",
            "Epoch 41/300\n",
            "125/125 [==============================] - 33s 264ms/step - loss: 0.2156 - accuracy: 0.8291\n",
            "Epoch 42/300\n",
            "125/125 [==============================] - 33s 263ms/step - loss: 0.2108 - accuracy: 0.8306\n",
            "Epoch 43/300\n",
            " 54/125 [===========>..................] - ETA: 18s - loss: 0.2060 - accuracy: 0.8511"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}