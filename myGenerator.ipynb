{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ticlemXaNyrIHoAawXiwNA6ZYyktxHpg",
      "authorship_tag": "ABX9TyPcKEciibarsHXMDz355U2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enverakbacak/EMIR/blob/main/myGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3R9rpEBrAK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dMXK7DdlEYN"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uEsYlKUCtaq"
      },
      "source": [
        "cd drive/MyDrive/ColabNotebooks/generators/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEjO8gzuR61z"
      },
      "source": [
        "#coding=utf-8\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import sys,os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import time\n",
        "import glob\n",
        "import os, os.path\n",
        "import re\n",
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDdIl4lTSE0L"
      },
      "source": [
        "def generator(samples, labels, batch_size=32):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        " \n",
        "    while True: # Loop forever so the generator never terminates\n",
        "      \n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            label_samples = labels[offset:offset+batch_size]\n",
        "             \n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            y_train = [] \n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "              filename = 'Lamda/images/' + batch_sample[0] + '.jpg'\n",
        "              image = plt.imread(filename)\n",
        "              # Read label (y)\n",
        "              X_train.append(image)\n",
        "            X_train = np.array(X_train)\n",
        "            #from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "            #X_train = preprocess_input(X_train) # preprocessing the input data\n",
        "            \n",
        "            for label_sample in label_samples:\n",
        "              y_train.append(label_sample) \n",
        "            y_train = np.array(y_train)            \n",
        "            \n",
        "\n",
        "            # The generator-y part: yield the next training batch\n",
        "            yield X_train, y_train\n",
        "    \n",
        "\n",
        "# Import list of train and validation data (image filenames and image labels)\n",
        "# Note this is not valid code."
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb1GpKNeUzFP",
        "outputId": "a72c55f8-5478-49bf-f977-a494c4e63666"
      },
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "print(len(data))\n",
        "labels = pd.read_csv('Y.csv')\n",
        "labels.shape\n",
        "print(labels.shape[:])\n",
        "\n",
        "labels = np.asarray(labels).astype('float32').reshape((-1,1))\n",
        "print(labels.shape[:])\n",
        "\n",
        "# Create generator\n",
        "train_generator = generator(data, labels, batch_size=32)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999\n",
            "(1999, 5)\n",
            "(9995, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGJBubtbVkTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d647b9-624e-48ca-b88e-d03d0e3db94d"
      },
      "source": [
        "image_size = 229\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "batch_size = 32\n",
        "hash_bits = 16\n",
        "inputs    = tensorflow.keras.Input(shape = (image_size, image_size,3))\n",
        "x         = base_model(inputs)\n",
        "#flatten   = Flatten()(x)\n",
        "Dense_1   = Dense(1024)(x)\n",
        "avgPool = GlobalAveragePooling2D()(Dense_1)\n",
        "Dense_2 = Dense(hash_bits ,activation='tanh')(avgPool)\n",
        "Dense_3 = Dense(5, activation='sigmoid')(Dense_2)\n",
        "model = Model(inputs, Dense_3)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "def c_loss_1(y_true, y_pred):\n",
        "    return  tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def c_loss_2(noise_1, noise_2):\n",
        "    noise_1 = tf.cast(Dense_2 > 0.5 , tf.float32 )\n",
        "    noise_2 = Dense_2 \n",
        "    return  tf.keras.losses.binary_crossentropy(noise_1, noise_2)\n",
        "model.compile(loss = [c_loss_1, c_loss_2],  optimizer=sgd, metrics=['accuracy'],)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 229, 229, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5, 5, 1024)        2098176   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                16400     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 85        \n",
            "=================================================================\n",
            "Total params: 23,917,445\n",
            "Trainable params: 2,114,661\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGNPNyRUVqib"
      },
      "source": [
        "model.fit_generator(train_generator, verbose=1, steps_per_epoch = 2000/32, epochs=32)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}